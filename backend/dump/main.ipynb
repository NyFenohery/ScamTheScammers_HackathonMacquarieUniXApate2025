{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "104ff9bc",
   "metadata": {},
   "source": [
    "### Load + preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b8b5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import hdbscan\n",
    "import json\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"datasets/Nigerian_Fraud.csv\")\n",
    "\n",
    "# Combine subject+body as full conversation text\n",
    "df[\"full_text\"] = (\n",
    "    df[\"subject\"].fillna(\"\") + \" \" + df[\"body\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "# Basic cleaning\n",
    "def clean(t):\n",
    "    t = str(t).lower()\n",
    "    t = re.sub(r\"http\\S+\", \"\", t)   # remove URLs\n",
    "    t = re.sub(r\"[^a-z0-9 ]\", \" \", t)\n",
    "    return t\n",
    "\n",
    "df[\"clean_text\"] = df[\"full_text\"].apply(clean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c237b510",
   "metadata": {},
   "source": [
    "### tf-idf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54828a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=3000, stop_words=\"english\")\n",
    "X = tfidf.fit_transform(df[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a3129",
   "metadata": {},
   "source": [
    "### clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df4595d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=10,\n",
    "    metric=\"euclidean\"\n",
    ")\n",
    "\n",
    "df[\"cluster\"] = clusterer.fit_predict(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09702155",
   "metadata": {},
   "source": [
    "## build json files for figma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d61499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters.json\n",
    "\n",
    "clusters_json = []\n",
    "\n",
    "for cid in sorted(df[\"cluster\"].unique()):\n",
    "    if cid == -1:\n",
    "        continue  # skip noise\n",
    "    \n",
    "    subset = df[df[\"cluster\"] == cid]\n",
    "    keywords = (\n",
    "        \" \".join(subset[\"clean_text\"].tolist())\n",
    "        .split()\n",
    "    )\n",
    "    top_keywords = pd.Series(keywords).value_counts().head(8).index.tolist()\n",
    "\n",
    "    clusters_json.append({\n",
    "        \"persona_id\": f\"C{cid:03d}\",\n",
    "        \"name\": f\"Persona {cid}\",\n",
    "        \"risk\": int(np.random.randint(40, 96)),\n",
    "        \"keywords\": top_keywords,\n",
    "        \"description\": \"Auto-generated scam persona based on text similarity.\",\n",
    "        \"archetype\": \"Generic Scam\"\n",
    "    })\n",
    "\n",
    "with open(\"json_files/clusters.json\", \"w\") as f:\n",
    "    json.dump(clusters_json, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2274940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# personas.json\n",
    "\n",
    "personas_json = {}\n",
    "\n",
    "for cid in sorted(df[\"cluster\"].unique()):\n",
    "    if cid == -1: \n",
    "        continue\n",
    "    \n",
    "    subset = df[df[\"cluster\"] == cid]\n",
    "    avg_len = int(subset[\"clean_text\"].apply(len).mean())\n",
    "    \n",
    "    personas_json[f\"C{cid:03d}\"] = {\n",
    "        \"name\": f\"Persona {cid}\",\n",
    "        \"traits\": {\n",
    "            \"tone\": \"Formal\",\n",
    "            \"emoji_rate\": \"low\",\n",
    "            \"script_score\": float(np.random.rand()),\n",
    "            \"avg_message_length\": avg_len,\n",
    "            \"common_phrases\": [],\n",
    "            \"tactics\": [\"urgency\", \"money-request\"],\n",
    "            \"platform\": [\"Email\"]\n",
    "        },\n",
    "        \"active_hours\": [9, 10, 11, 12, 13],\n",
    "        \"risk_score\": int(np.random.randint(50, 100)),\n",
    "        \"archetype\": \"Generic Scam\",\n",
    "        \"color\": \"#3b82f6\",\n",
    "        \"crew_id\": f\"CREW_{cid}\",\n",
    "        \"first_seen\": \"2024-01-01\",\n",
    "        \"last_seen\": \"2024-12-31\",\n",
    "        \"success_rate\": int(np.random.randint(1, 40)),\n",
    "        \"conversations\": len(subset)\n",
    "    }\n",
    "\n",
    "with open(\"json_files/personas.json\", \"w\") as f:\n",
    "    json.dump(personas_json, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de928a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24824\\1871550752.py:10: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"start_time\": datetime.utcnow().isoformat(),\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_24824\\1871550752.py:11: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"end_time\": datetime.utcnow().isoformat(),\n"
     ]
    }
   ],
   "source": [
    "# conversations.json\n",
    "\n",
    "conversations_json = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    conversations_json.append({\n",
    "        \"persona_id\": f\"C{int(row['cluster']):03d}\",\n",
    "        \"conversation_id\": f\"conv_{i:04d}\",\n",
    "        \"platform\": \"Email\",\n",
    "        \"start_time\": datetime.utcnow().isoformat(),\n",
    "        \"end_time\": datetime.utcnow().isoformat(),\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"sender\": \"scammer\",\n",
    "                \"text\": row[\"full_text\"][:500],\n",
    "                \"time\": \"10:23\",\n",
    "                \"flags\": [\"urgency\"] if \"urgent\" in row[\"clean_text\"] else []\n",
    "            }\n",
    "        ],\n",
    "        \"classification\": \"Generic Scam\",\n",
    "        \"outcome\": \"ongoing\"\n",
    "    })\n",
    "\n",
    "with open(\"json_files/conversations.json\", \"w\") as f:\n",
    "    json.dump(conversations_json, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f25b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_graph.json\n",
    "\n",
    "import itertools\n",
    "\n",
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "# Create nodes\n",
    "for cid in sorted(df[\"cluster\"].unique()):\n",
    "    if cid == -1:\n",
    "        continue\n",
    "    nodes.append({\n",
    "        \"id\": f\"C{cid:03d}\",\n",
    "        \"label\": f\"Persona {cid}\",\n",
    "        \"group\": f\"CREW_{cid}\"\n",
    "    })\n",
    "\n",
    "# Create simple similarity edges\n",
    "for (cid1, cid2) in itertools.combinations(sorted(df[\"cluster\"].unique()), 2):\n",
    "    if cid1 == -1 or cid2 == -1:\n",
    "        continue\n",
    "    \n",
    "    edges.append({\n",
    "        \"source\": f\"C{cid1:03d}\",\n",
    "        \"target\": f\"C{cid2:03d}\",\n",
    "        \"weight\": float(np.random.uniform(0.1, 1.0)),\n",
    "        \"type\": \"tactic\"\n",
    "    })\n",
    "\n",
    "graph_json = {\"nodes\": nodes, \"edges\": edges}\n",
    "\n",
    "with open(\"json_files/similarity_graph.json\", \"w\") as f:\n",
    "    json.dump(graph_json, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e04d68",
   "metadata": {},
   "source": [
    "### fastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03158cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import json\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"]\n",
    ")\n",
    "\n",
    "@app.get(\"/api/clusters.json\")\n",
    "def get_clusters():\n",
    "    return json.load(open(\"json_files/clusters.json\"))\n",
    "\n",
    "@app.get(\"/api/personas.json\")\n",
    "def get_personas():\n",
    "    return json.load(open(\"json_files/personas.json\"))\n",
    "@app.get(\"/api/conversations.json\")\n",
    "def get_conversations():\n",
    "    return json.load(open(\"json_files/conversations.json\"))\n",
    "\n",
    "@app.get(\"/api/similarity_graph.json\")\n",
    "def get_graph():\n",
    "    return json.load(open(\"json_files/similarity_graph.json\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
